<!DOCTYPE html>
<html lang="zh-CN">
<head><!-- hexo injector head_begin start --><!-- Google tag (gtag.js) --> <script async src="https://www.googletagmanager.com/gtag/js?id=G-K4DEGPDYSW"></script> <script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag("js", new Date()); gtag("config", "G-K4DEGPDYSW"); </script><!-- hexo injector head_begin end -->
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.2">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/logo.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/logo.png">
  <link rel="mask-icon" href="/images/logo.png" color="#222">
  <meta name="google-site-verification" content="oFhcvcGsjsTY5AFUaI-ezbn7-bel9NrdUNpeQfwZSwI">
  <meta name="msvalidate.01" content="F8E2F274161B653649F8818FD127CE87">
  <meta name="yandex-verification" content="f6d91994ba785a63">
  <meta name="baidu-site-verification" content="code-nNL5JO7sPl">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"finisky.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.5.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>
<meta name="description" content="微信最近有篇新闻刷屏： # 微信推出自研NLP大规模语言模型WeLM：零&#x2F;少样本即可完成多种NLP任务 来看看这背后的技术原理又是什么： WeLM: A Well-Read Pre-trained Language Model for Chinese">
<meta property="og:type" content="article">
<meta property="og:title" content="WeLM: A Well-Read Pre-trained Language Model for Chinese 简读">
<meta property="og:url" content="https://finisky.github.io/welm-paper-summary/index.html">
<meta property="og:site_name" content="Finisky Garden">
<meta property="og:description" content="微信最近有篇新闻刷屏： # 微信推出自研NLP大规模语言模型WeLM：零&#x2F;少样本即可完成多种NLP任务 来看看这背后的技术原理又是什么： WeLM: A Well-Read Pre-trained Language Model for Chinese">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmexample.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmdatastats.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmmodeldetails.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmcnresult.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmlibai.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/weprompttasks.png">
<meta property="og:image" content="https://coriva.eu.org/images/nlp/welmselfcalibration.png">
<meta property="article:published_time" content="2022-10-17T11:57:10.000Z">
<meta property="article:modified_time" content="2022-10-17T12:07:12.000Z">
<meta property="article:author" content="finisky">
<meta property="article:tag" content="Machine Learning">
<meta property="article:tag" content="NLP">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="NLG">
<meta property="article:tag" content="Language Model">
<meta property="article:tag" content="Prompt">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://coriva.eu.org/images/nlp/welmexample.png">


<link rel="canonical" href="https://finisky.github.io/welm-paper-summary/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://finisky.github.io/welm-paper-summary/","path":"welm-paper-summary/","title":"WeLM: A Well-Read Pre-trained Language Model for Chinese 简读"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>WeLM: A Well-Read Pre-trained Language Model for Chinese 简读 | Finisky Garden</title>
  



<link rel="dns-prefetch" href="https://comments.finisky.eu.org">
  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<!-- hexo injector head_end start --><script type="text/javascript"> function downloadJsAtOnload() { setTimeout(function downloadJs() { var element = document.createElement("script"); element.setAttribute("data-ad-client", "ca-pub-2660281922577700"); element.async = true; element.src = "https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"; document.body.appendChild(element); }, 5000); }; if (window.addEventListener) window.addEventListener("load", downloadJsAtOnload, false); else if (window.attachEvent) window.attachEvent("onload", downloadJsAtOnload); else window.onload = downloadJsAtOnload; </script><!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="Finisky Garden" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Finisky Garden</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">NLP, 软件工程, 产品设计, 职业生涯</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li>
        <li class="menu-item menu-item-nlp"><a href="/tags/NLP/" rel="section"><i class="fa fa-language fa-fw"></i>NLP</a></li>
        <li class="menu-item menu-item-mongodb"><a href="/categories/MongoDB/" rel="section"><i class="fas fa-database fa-fw"></i>MongoDB</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li>
        <li class="menu-item menu-item-links"><a href="/links/" rel="section"><i class="fas fa-link fa-fw"></i>友链</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#welm%E7%AE%80%E4%BB%8B"><span class="nav-number">1.</span> <span class="nav-text">WeLM简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE"><span class="nav-number">2.</span> <span class="nav-text">训练数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8B"><span class="nav-number">3.</span> <span class="nav-text">模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C"><span class="nav-number">4.</span> <span class="nav-text">实验</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#multitask-prompted-training"><span class="nav-number">5.</span> <span class="nav-text">Multitask Prompted Training</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">6.</span> <span class="nav-text">总结</span></a></li></ol></div>
            <div class="site-author site-overview-item animated">
              <img class="site-author-image" itemprop="image" alt="finisky" src="/images/qrcode.jpg" />
              <p class="site-author-name">扫码关注公众号</p>
            </div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-overview">
            <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="finisky"
      src="/images/qrcode.jpg">
  <p class="site-author-name">扫码关注公众号</p>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">209</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">14</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">60</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



          </div>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://finisky.github.io/welm-paper-summary/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/qrcode.jpg">
      <meta itemprop="name" content="finisky">
      <meta itemprop="description" content="互联网那些事儿：NLP, 软件工程, 产品设计, 职业生涯">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Finisky Garden">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          WeLM: A Well-Read Pre-trained Language Model for Chinese 简读
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2022-10-17 19:57:10 / 修改时间：20:07:12" itemprop="dateCreated datePublished" datetime="2022-10-17T19:57:10+08:00">2022-10-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Machine-Learning/" itemprop="url" rel="index"><span itemprop="name">Machine Learning</span></a>
        </span>
    </span>

  
  
  <span class="post-meta-item">
    
    <span class="post-meta-item-icon">
      <i class="far fa-comment"></i>
    </span>
    <span class="post-meta-item-text">评论：</span>
  
    <a title="waline" href="/welm-paper-summary/#waline" itemprop="discussionUrl">
      <span class="post-comments-count waline-comment-count" data-path="/welm-paper-summary/" itemprop="commentCount"></span>
    </a>
  </span>
  
  
    <span class="post-meta-item" title="阅读次数">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span class="waline-pageview-count" data-path="/welm-paper-summary/"></span>
    </span>
  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <p>微信最近有篇新闻刷屏： <a
target="_blank" rel="noopener" href="https://new.qq.com/rain/a/20221013A02P8400">#
微信推出自研NLP大规模语言模型WeLM：零/少样本即可完成多种NLP任务</a></p>
<p>来看看这背后的技术原理又是什么：</p>
<p><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2209.10372">WeLM: A Well-Read
Pre-trained Language Model for Chinese</a></p>
<span id="more"></span>
<h1 id="welm简介">WeLM简介</h1>
<p>WeLM是什么？是一个多任务零样本或小样本学习的中文预训练语言模型：</p>
<blockquote>
<p>A well-read pre-trained language model for Chinese that is able to
seamlessly perform different types of tasks with zero or few-shot
demonstrations.</p>
</blockquote>
<p>WeLM 有 10B 的参数（与GPT3 的 175B，和 Ernie 3.0 260B
的参数相比并不算很大），经过仔细的数据清洗、平衡数据源及增大训练数据规模，它的性能可以显著超过同样大小的其他模型。</p>
<blockquote>
<p>We show that by carefully cleaning the data, balancing out data
sources and scaling up the training data size, WeLM is able to
significantly outperform existing models with similar sizes. On zeroshot
evaluations, it can match the performance of Ernie 3.0 Titan that is 25x
larger.</p>
</blockquote>
<p>WeLM的几个特点：</p>
<ul>
<li>多语言理解，在机器翻译、QA和摘要任务上都超过了有30种语言进行预训练的
XGLM 。在中日英三国语言混写的情况下(code-switching
translation)，WeLM也能正确地翻译。</li>
<li>通过人工手写的prompts，WeLM可以在未见过的任务上有更好的泛化能力。</li>
<li>WeLM还能解释和调整自己做的一些决定。</li>
</ul>
<p><img src="https://coriva.eu.org/images/nlp/welmexample.png"
alt="WeLM Illustration" /></p>
<h1 id="训练数据">训练数据</h1>
<p>同时使用了中英文数据，总数据的原始文本大小超过了
10T。清洗数据的过程非常细，只保留正面数据，通过规则和一个二分类器过滤掉87.5%的数据。用MD5和SimHash的方式去掉40.02%的重复数据。用
17-gram 匹配的方式，去掉了剩下数据中的0.15%。</p>
<p>经过以上几步清洗，还剩下 262B
tokens的数据。对这些数据进行重采样，以保证数据的多样性。</p>
<p>重采样后训练数据的统计信息：</p>
<p><img src="https://coriva.eu.org/images/nlp/welmdatastats.png"
alt="WeLM Data Stats" /></p>
<h1 id="模型">模型</h1>
<p>基于 Megatron-LM 和 DeepSpeed 进行训练。模型结构与 GPT3的 自回归
Transformer 相同，主要区别：</p>
<ul>
<li>Relative encodings:
对长文本语义更友好，本文的任务会涉及完整文章或书籍的处理。</li>
<li>Vocabulary: SentencePiece tokenizer，62K tokens。其中中文token有 30K
，其余的是英文、日文和韩文。</li>
</ul>
<p>共训练了3个（原文有typo）不同大小的模型，采用 AdamW optimizer，FP16
混合精度训练：</p>
<p><img src="https://coriva.eu.org/images/nlp/welmmodeldetails.png"
alt="WeLM Model Details" /></p>
<p>训练成本很可观，最大的模型用128块 A100 训练了24天：</p>
<blockquote>
<p>The largest model is trained on 128 A100-SXM4-40GB GPUs in about 24
days.</p>
</blockquote>
<p>由于训练不稳定，有一些训练的tricks，在大模型训练中比较要命，一旦train废了，大把钱就白花了，文中的处理方案：</p>
<blockquote>
<p>We observe some instability issues when training the 10B-sized model.
The training loss could suddenly increase in one batch then falls down.
This loss spike, when happening frequently, would deteriorate the model
weights and slows down the convergence. We mitigate this issue by
re-starting the training from a checkpoint roughly 100 steps before the
spike happened, then skipping the following 200 data batches. We also
find it helps to reduce the learning rate and reset the dynamic loss
scale.</p>
</blockquote>
<h1 id="实验">实验</h1>
<p>在18个中文NLP任务上，与CPM/Pangu/Ernie
3.0(10B)相比，多数情况下WeLM的性能最优：</p>
<p><img src="https://coriva.eu.org/images/nlp/welmcnresult.png"
alt="WeLM Chinese NLP Tasks Result" /></p>
<p>看下我们关注的文本生成任务，WeLM作文本生成主要靠prompt。看它如何扮演李白的角色，注意，在这段对话中还有中英夹杂的情况：</p>
<p><img src="https://coriva.eu.org/images/nlp/welmlibai.png"
alt="WeLM Li Bai" /></p>
<p>这里的对话还是挺有意思的，生成的回复也不局限于前面的prompt，还有一些额外的知识引入，不过与
Google 的
LaMDA相比，此处并没有搜索引擎的加持，而只是大模型本身的记忆。</p>
<h1 id="multitask-prompted-training">Multitask Prompted Training</h1>
<p>此外，作者还探索了是否可以通过显式的多任务学习来加强模型的泛化能力。方法是用人工写的不同任务的prompts训练模型，称做<strong>WePrompt</strong>。为属于14个类别的76个任务手写了
1227 个 prompts 模板：</p>
<p><img src="https://coriva.eu.org/images/nlp/weprompttasks.png"
alt="WePrompt Tasks" /></p>
<p>训练数据的构造：从76个任务中随机选择一个，再从该任务中采样一条标注数据和一条prompt模板，并通过这个模板构造一条自然语言训练数据，重复上述过程直到将这个句子达到2048
tokens。最后使用这些构造的数据fine-tune WeLM得到WePrompt。</p>
<p>WePrompt的效果自不必提，不过这解释了为什么WeLM要通过Prompt的方式进行使用：因为它是通过prompt
tuning的方式进行训练的。</p>
<p>最后，模型还尝试了可解释性与自我纠错。看看下面这个自我纠错的例子：</p>
<p><img src="https://coriva.eu.org/images/nlp/welmselfcalibration.png"
alt="WeLM Self-Calibration" /></p>
<h1 id="总结">总结</h1>
<p>WeLM通过筛选高质量训练数据，跨语言训练并使用prompt
tuning的方式提升模型的性能，在零样本和小样本学习中达到很好的效果。</p>
<p>目前看到的大模型基本都是采用与GPT3相同的自回归结构，与LaMDA一样，WeLM也花了不少功夫在筛选训练数据上面，不同的是，WeLM主要采用prompt进行推断。</p>
<p>目前看到的性能优良的模型，在模型本身上的创新都不多，为达更好性能基本都靠高质量数据与大力出奇迹。</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/finisky-bot/" rel="bookmark">小菲陪您唠唠磕</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/blenderbot3-summary/" rel="bookmark">BlenderBot 3 对话系统简析</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/briefintrotoprompt.en/" rel="bookmark">Brief Introduction to NLP Prompting</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/briefintrotoprompt/" rel="bookmark">NLP Prompt技术简介</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/chatgpt-for-official-account/" rel="bookmark">为什么不接ChatGPT到微信公号？</a></div>
    </li>
  </ul>


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
              <a href="/tags/NLP/" rel="tag"># NLP</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
              <a href="/tags/NLG/" rel="tag"># NLG</a>
              <a href="/tags/Language-Model/" rel="tag"># Language Model</a>
              <a href="/tags/Prompt/" rel="tag"># Prompt</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/lamda-paper-summary/" rel="prev" title="LaMDA: Language Models for Dialog Applications 简读">
                  <i class="fa fa-chevron-left"></i> LaMDA: Language Models for Dialog Applications 简读
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/muyu-app/" rel="next" title="这么个玩意儿也能赚钱？">
                  这么个玩意儿也能赚钱？ <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments" id="waline"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">finisky</span>
</div><div><span class="post-meta-item-icon"><i class="far fa-eye"></i></span><span><a href="https://finicounter.eu.org/" target="_blank">Total Views</a>:</span><span id="finicount_views" style="display:inline;padding-left:5px;"></span><div> <script async src="//finicounter.eu.org/finicounter.js"></script>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/next-boot.js"></script>

  




  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.1.4/es5/tex-mml-chtml.js","integrity":"sha256-ncNI9OXOS5Ek4tzVYiOMmN/KKCPZ6V0Cpv2P/zHntiA="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="waline" type="application/json">{"lang":"en-US","enable":true,"serverURL":"https://comments.finisky.eu.org","cssUrl":"https://unpkg.com/@waline/client@v2/dist/waline.css","commentCount":true,"pageview":true,"pageSize":10,"el":"#waline","comment":true,"libUrl":"//unpkg.com/@waline/client@v2/dist/waline.js","path":"/welm-paper-summary/"}</script>
<link rel="stylesheet" href="https://unpkg.com/@waline/client@v2/dist/waline.css">
<script>
document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});
</script>

<script>
            window.imageLazyLoadSetting = {
                isSPA: false,
                preloadRatio: 1,
                processImages: null,
            };
        </script><script>window.addEventListener("load",function(){var t=/\.(gif|jpg|jpeg|tiff|png)$/i,r=/^data:image\/[a-z]+;base64,/;Array.prototype.slice.call(document.querySelectorAll("img[data-original]")).forEach(function(a){var e=a.parentNode;"A"===e.tagName&&(e.href.match(t)||e.href.match(r))&&(e.href=a.dataset.original)})});</script><script>!function(n){n.imageLazyLoadSetting.processImages=o;var e=n.imageLazyLoadSetting.isSPA,i=n.imageLazyLoadSetting.preloadRatio||1,r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function o(){e&&(r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]")));for(var t,a=0;a<r.length;a++)0<=(t=(t=r[a]).getBoundingClientRect()).bottom&&0<=t.left&&t.top<=(n.innerHeight*i||document.documentElement.clientHeight*i)&&function(){var t,e,n,i,o=r[a];t=o,e=function(){r=r.filter(function(t){return o!==t})},n=new Image,i=t.getAttribute("data-original"),n.onload=function(){t.src=i,e&&e()},t.src!==i&&(n.src=i)}()}o(),n.addEventListener("scroll",function(){var t,e;t=o,e=n,clearTimeout(t.tId),t.tId=setTimeout(function(){t.call(e)},500)})}(this);</script></body>
</html>
