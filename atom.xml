<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Finisky Garden</title>
  <icon>https://finisky.github.io/icon.png</icon>
  <subtitle>NLP, 软件工程, 产品设计</subtitle>
  <link href="https://finisky.github.io/atom.xml" rel="self"/>
  
  <link href="https://finisky.github.io/"/>
  <updated>2023-05-11T09:28:57.000Z</updated>
  <id>https://finisky.github.io/</id>
  
  <author>
    <name>finisky</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>升级gcc解决编译llama-cpp-python错误</title>
    <link href="https://finisky.github.io/build-llama-cpp-python-error-solution/"/>
    <id>https://finisky.github.io/build-llama-cpp-python-error-solution/</id>
    <published>2023-05-11T09:18:39.000Z</published>
    <updated>2023-05-11T09:28:57.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;安装 &lt;a
href=&quot;https://github.com/oobabooga/text-generation-webui&quot;&gt;text-generation-webui&lt;/a&gt;&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-bash&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;~/text-generation-webui$ pip &lt;span class=&quot;token function&quot;&gt;install&lt;/span&gt; &lt;span class=&quot;token parameter variable&quot;&gt;-r&lt;/span&gt; requirements.txt&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;遇到错误：&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>ERROR: Could not find a version that satisfies the requirement Solution</title>
    <link href="https://finisky.github.io/en/could-not-find-a-version-that-satisfies-the-requirement-solution/"/>
    <id>https://finisky.github.io/en/could-not-find-a-version-that-satisfies-the-requirement-solution/</id>
    <published>2023-05-10T09:05:16.000Z</published>
    <updated>2023-05-10T09:13:16.000Z</updated>
    
    
    <summary type="html">&lt;pre class=&quot;line-numbers language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;$ pip install torch&amp;#x3D;&amp;#x3D;1.12.0
Defaulting to user installation because normal site-packages is not writeable
ERROR: Could not find a version that satisfies the requirement torch&amp;#x3D;&amp;#x3D;1.12.0 (from versions: 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2)
ERROR: No matching distribution found for torch&amp;#x3D;&amp;#x3D;1.12.0&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The root cause is that python version is too low (&lt;code&gt;3.6&lt;/code&gt;).
We need to upgrade python to a new version.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="python" scheme="https://finisky.github.io/tags/python/"/>
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>贵州4月下旬自驾游记</title>
    <link href="https://finisky.github.io/guizhou/"/>
    <id>https://finisky.github.io/guizhou/</id>
    <published>2023-05-04T01:12:01.000Z</published>
    <updated>2023-05-10T09:13:16.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;好久没出去看大好河山，五一前休假去贵州自驾游，云贵川算是都打了卡。按照惯例，还是提前简单做下攻略，本想将行程设置宽松些，后来发现贵州的大部分景点门票预订（进景区时间）都要精确到小时，才不得不把行程提前细化。&lt;/p&gt;
&lt;p&gt;贵州的主要景点也比较分散，不过都是以省会贵阳为中心放射状排列，本次自驾主要以黔东为主。之前找到一张不错的贵州景点分布图，记不清出处了：&lt;/p&gt;</summary>
    
    
    
    <category term="Life" scheme="https://finisky.github.io/categories/Life/"/>
    
    
    <category term="自驾游" scheme="https://finisky.github.io/tags/%E8%87%AA%E9%A9%BE%E6%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>围炉对谈：OpenAI创始人对GPT-4和ChatGPT的理解</title>
    <link href="https://finisky.github.io/fireside-talk-openai-ceo-summary/"/>
    <id>https://finisky.github.io/fireside-talk-openai-ceo-summary/</id>
    <published>2023-03-30T11:02:03.000Z</published>
    <updated>2023-03-30T11:05:14.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;3月22日，NVIDIA的CEO黄仁勋与OpenAI的创始人Ilya
Sutskever进行了围炉对谈，通过视频可以更好地了解OpenAI是如何走到今天，又是如何理解ChatGPT和GPT-4这些大模型的。不过毕竟是非正式访谈，思路和观点略有发散，本文提取访谈中一些有意思的观点供参考。&lt;/p&gt;
&lt;p&gt;BTW，网上的中文完整字幕翻译对某些观点的翻译解读有误，建议看原视频。&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://blogs.nvidia.com/blog/2023/03/22/sutskever-openai-gtc/&quot;&gt;#
AI Opener: OpenAI’s Sutskever in Conversation With Jensen Huang&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>力洛克T41自行洗油保养实录</title>
    <link href="https://finisky.github.io/lelocle-maintain/"/>
    <id>https://finisky.github.io/lelocle-maintain/</id>
    <published>2023-03-05T15:49:05.000Z</published>
    <updated>2023-03-05T16:05:46.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;戴了十几年的力洛克，一年前开始走时不准，最近每天能慢上一分钟，手动上弦似乎也有些问题，总是上不满弦，怀疑与之前疫情在家总手动上弦有关系
(最初怀疑发条断了)。&lt;/p&gt;
&lt;p&gt;距上次保养已经5年有余，天梭官方授权的店保养一次 (所谓完全服务)
约一千块，而买块新的ETA-2824-2机芯也就差不多这个价，所以再去保养显得非常不划算。老爷子年轻时玩表修表，有此家学，再加上网上有许多机芯拆解洗油点油视频，看起来也不甚困难，跃跃欲试，决定自行保养维护。&lt;/p&gt;
&lt;p&gt;前后历时一个月才保养完毕，趟坑无数。现在看来，动手时显然低估了保养洗油的难度，加之中间遇到的诸多难题，本想从玩表的过程获取些操作的成就感，不想却收获了诸多挫败感。修完后才感叹，授权店收一千块算是良心价了
:-) 。好在最终问题完美解决，记录下保养过程。&lt;/p&gt;</summary>
    
    
    
    <category term="Life" scheme="https://finisky.github.io/categories/Life/"/>
    
    
  </entry>
  
  <entry>
    <title>Chain-of-Thought Prompting 简读</title>
    <link href="https://finisky.github.io/chain-of-thought-prompting-summary/"/>
    <id>https://finisky.github.io/chain-of-thought-prompting-summary/</id>
    <published>2023-03-01T11:39:00.000Z</published>
    <updated>2023-03-01T11:45:49.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;语言模型越来越大，但更大的模型并没有显示出更强的计算和推理能力。去年Google提出了Chain-of-Thought
(CoT)
的方案，通过chain-of-thought提示，让模型逐步推断，使大模型的推理能力显著提升。本文来看一下chain-of-thought的原理。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2201.11903&quot;&gt;Chain-of-Thought Prompting
Elicits Reasoning in Large Language Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://ai.googleblog.com/2022/05/language-models-perform-reasoning-via.html&quot;&gt;Language
Models Perform Reasoning via Chain of Thought&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>大模型训练不稳定问题及解决方案</title>
    <link href="https://finisky.github.io/llm-training-instability-solution/"/>
    <id>https://finisky.github.io/llm-training-instability-solution/</id>
    <published>2023-02-15T02:08:12.000Z</published>
    <updated>2023-02-15T09:47:17.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;大规模语言模型的春风已经吹遍大地，大家都惊叹于大模型出色的对话能力，但是在训练大模型时遇到的训练不稳定问题(&lt;strong&gt;training
instabilities&lt;/strong&gt;)，可能关注的人并不太多。所谓量变引起质变，模型每大一个量级，就可能会出现一些意想不到的问题，比如莫名其妙的训练崩溃。当然，也有好的方面，在模型有一定规模后，是否有可能表现出一些弱智能，也很难说。&lt;/p&gt;
&lt;p&gt;言归正传，今天聊聊在训练10B以上模型时遇到的训练不稳定现象，问题原因及当前的解法。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Google拟发布ChatGPT的竞争对手Bard</title>
    <link href="https://finisky.github.io/google-open-bard-to-trusted-testers/"/>
    <id>https://finisky.github.io/google-open-bard-to-trusted-testers/</id>
    <published>2023-02-08T11:55:39.000Z</published>
    <updated>2023-02-08T11:57:54.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;ChatGPT的大火让Google也坐不住了，许多人认为这一波Google已落后一个身位。坊间甚至传言创始人谢尔盖・布林都已“躬身入局”，亲自写代码了。上面的说法可以当八卦看来一乐，不过昨天微软官宣Bing和Edge浏览器要集成ChatGPT时，Google也不甘示弱，表示也要上线大模型&lt;code&gt;Bard&lt;/code&gt;
(这个名字倒也颇具浪漫主义气质：吟游诗人)。&lt;/p&gt;</summary>
    
    
    
    <category term="News" scheme="https://finisky.github.io/categories/News/"/>
    
    
  </entry>
  
  <entry>
    <title>大模型分布式训练的并行策略</title>
    <link href="https://finisky.github.io/how-to-train-large-language-model/"/>
    <id>https://finisky.github.io/how-to-train-large-language-model/</id>
    <published>2023-02-02T15:32:10.000Z</published>
    <updated>2023-02-08T11:57:54.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;随着神经网络模型规模的不断增大，对硬件的显存和算力提出了新的要求。首先模型参数过多，导致单机内存放不下，即使能放得下，算力也跟不上。同时，硬件算力的增长远远比不上模型增长的速度，单机训练变得不再可行，需要并行化分布式训练加速。比如&lt;code&gt;Megatron-Turing NLG&lt;/code&gt;有
530B 的参数，训练需要超过 10T 的内存来存储权重、梯度和状态。&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://coriva.eu.org/images/nlp/trendofnlpmodelsize.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;同时，模型是一个有机的整体，简单增加机器数量并不能提升算力，需要有并行策略和通信设计，才能实现高效的并行训练。本文简要介绍目前主流的几种并行策略：数据并行，张量并行，流水线并行和混合并行。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2201.11990&quot;&gt;# Using DeepSpeed and
Megatron to Train Megatron-Turing NLG 530B, A Large-Scale Generative
Language Model&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT推出了收费版，每月20刀</title>
    <link href="https://finisky.github.io/chatgpt-plus/"/>
    <id>https://finisky.github.io/chatgpt-plus/</id>
    <published>2023-02-02T02:19:00.000Z</published>
    <updated>2023-02-08T11:57:54.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;近来被人们玩坏的ChatGPT推出了收费订阅&lt;code&gt;ChatGPT Plus&lt;/code&gt;，每月20刀，提供更好的可用性，更快的回复时间，和提前试用新功能的权益。&lt;/p&gt;
&lt;p&gt;这个订阅目前仅对美国地区开放，先从之前登记的waitlist上邀请试用，后续会开放更多国家和地区。&lt;/p&gt;
&lt;p&gt;好消息是免费版继续可用，推出收费版后可以更好地服务于更多的免费用户。&lt;/p&gt;</summary>
    
    
    
    <category term="News" scheme="https://finisky.github.io/categories/News/"/>
    
    
  </entry>
  
  <entry>
    <title>Hexo Set Environment Variable</title>
    <link href="https://finisky.github.io/en/how-to-set-hexo-env/"/>
    <id>https://finisky.github.io/en/how-to-set-hexo-env/</id>
    <published>2023-01-28T03:28:52.000Z</published>
    <updated>2023-01-28T03:31:50.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Recently I upgrade NexT theme to v8.14.1. The related post plugin
&lt;code&gt;hexo-related-popular-posts&lt;/code&gt; had been replaced by
&lt;code&gt;hexo-related-posts&lt;/code&gt;, which generates related posts by tf-idf
algorithm. However, the compute cost is a little bit heavy if you have
many posts. A good trade-off is enable this feature only for production
environment. The plugin &lt;a
href=&quot;https://github.com/sergeyzwezdin/hexo-related-posts&quot;&gt;hexo-related-posts&lt;/a&gt;
already takes this into account and use &lt;code&gt;enable_env_name&lt;/code&gt; to
disable its execution. Unfortunately, the document has typo so I takes
some time to fix it.&lt;/p&gt;
&lt;p&gt;So how to set environment variable in Hexo?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Short
Answer&lt;/strong&gt;：&lt;code&gt;$ hexo &amp;lt;command&amp;gt; --&amp;lt;env_key&amp;gt; env_value&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;The following secitons will illustrate how to enable related post on
production.&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
  </entry>
  
  <entry>
    <title>Hexo环境变量区分生产环境</title>
    <link href="https://finisky.github.io/how-to-set-hexo-env/"/>
    <id>https://finisky.github.io/how-to-set-hexo-env/</id>
    <published>2023-01-27T16:42:27.000Z</published>
    <updated>2023-01-27T16:50:30.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近升级NexT主题到最新版v8.14.1，相关文章功能从v8.10开始由&lt;code&gt;hexo-related-popular-posts&lt;/code&gt;替换成了&lt;code&gt;hexo-related-posts&lt;/code&gt;，后者是用tf-idf算法对文章全文进行相似度计算而得相关文章，比&lt;code&gt;hexo-related-popular-posts&lt;/code&gt;要精准和先进一些，不过副作用是计算量变大，在文章数较多的情况下运行会比较慢，这样在写完文章后用&lt;code&gt;hexo s&lt;/code&gt;进行本地调试效率就变低了，每次文章修改都要重新计算一遍tf-idf。好在
&lt;a
href=&quot;https://github.com/sergeyzwezdin/hexo-related-posts&quot;&gt;hexo-related-posts&lt;/a&gt;
考虑到了此问题，可以通过设置&lt;code&gt;enable_env_name&lt;/code&gt;变量，只在特定环境(如生产环境)中才开启此功能。不过文档略有些问题，费了一番周折才设置环境变量成功。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;短答案&lt;/strong&gt;：&lt;code&gt;$ hexo &amp;lt;command&amp;gt; --&amp;lt;env_key&amp;gt; env_value&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;长答案：本文介绍了如何使用环境变量仅在生产环境开启相关文章功能。&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
  </entry>
  
  <entry>
    <title>ETA 2824-2 机芯保养手册</title>
    <link href="https://finisky.github.io/eta-2824-2-manual/"/>
    <id>https://finisky.github.io/eta-2824-2-manual/</id>
    <published>2023-01-26T05:06:00.000Z</published>
    <updated>2023-01-30T07:57:08.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;ETA 2824-2
是经典的瑞士机芯之一，稳定、准确度高。网上也有一个很好的拆解点油视频：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.bilibili.com/video/BV1qJ411v7nQ/&quot;&gt;#
ETA2824机芯的保养与拆解组装过程&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;不过关于2824机芯的手册百度很难搜到免费下载，在此与表友共享。&lt;/p&gt;</summary>
    
    
    
    <category term="Life" scheme="https://finisky.github.io/categories/Life/"/>
    
    
  </entry>
  
  <entry>
    <title>Training Compute-Optimal Large Language Models 简读</title>
    <link href="https://finisky.github.io/training-compute-optimal-large-language-models-summary/"/>
    <id>https://finisky.github.io/training-compute-optimal-large-language-models-summary/</id>
    <published>2023-01-24T09:26:43.000Z</published>
    <updated>2023-01-24T09:57:45.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;DeepMind去年在 NeurIPS 2022
发表了一篇如何在给定计算资源条件下，用多少tokens训练最优大小的 Large
Language Models
(LLM)。之前的许多工作都仅专注于扩大模型规模，而并不增加训练数据规模，导致这些模型显著地训练不到位
(undertrained)。DeepMind训练用不同规模的数据 (从5B到500B tokens)
训练超过400个不同大小的模型 (从70M到超过16B)，发现
&lt;strong&gt;模型和训练数据规模需要同比增大&lt;/strong&gt;。根据这个假设，使用与
Gopher (280B) 同样的计算量且4倍的数据，训练了70B的最优模型
Chinchilla。它在许多下游任务上的性能显著超过了 Gopher (280B), GPT-3
(175B) Jurassic-1 (178B) 和 Megatron-Turing NLG (530B)。&lt;/p&gt;
&lt;p&gt;[NeurIPS 2022] &lt;a
href=&quot;https://openreview.net/pdf?id=iBBcRUlOAPR&quot;&gt;Training
Compute-Optimal Large Language Models&lt;/a&gt; &lt;a
href=&quot;https://arxiv.org/abs/2203.15556&quot;&gt;Training Compute-Optimal Large
Language Models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;本文的 Chinchilla 也是后续对话系统 &lt;a
href=&quot;/sparrow-summary/&quot;&gt;Sparrow&lt;/a&gt; 的基模型。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>微软与ChatGPT联手会带来什么？</title>
    <link href="https://finisky.github.io/why-microsoft-buy-chatgpt/"/>
    <id>https://finisky.github.io/why-microsoft-buy-chatgpt/</id>
    <published>2023-01-23T02:49:00.000Z</published>
    <updated>2023-01-23T10:07:16.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近微软投资ChatGPT的消息甚嚣尘上，二者的联手会给产业和用户带来什么？&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://www.reuters.com/technology/microsoft-talks-invest-10-bln-chatgpt-owner-semafor-2023-01-10/&quot;&gt;#
Microsoft in talks to invest $10 bln in ChatGPT-owner OpenAI&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;从新闻上来看，微软会将ChatGPT集成到Office和Bing
Search。但实际情况可能不止于此，微软擅长做平台，CVP已经在&lt;a
href=&quot;https://azure.microsoft.com/en-us/blog/general-availability-of-azure-openai-service-expands-access-to-large-advanced-ai-models-with-added-enterprise-benefits/&quot;&gt;Azure
Blog&lt;/a&gt;称ChatGPT将不久在Azure OpenAI Service上可用:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Customers will also be able to access ChatGPT—a fine-tuned version of
GPT-3.5 that has been trained and runs inference on Azure AI
infrastructure—through Azure OpenAI Service soon.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;好消息是这个服务可以直接让中小企业基于API研发产品而无须自行研发模型。坏消息是它的效果太好以至于自己训练的模型不能达到同水平的效果，形成对此底层服务的强依赖。&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Git Sync Remote Branch Automatically by Webhook</title>
    <link href="https://finisky.github.io/en/git-sync-remote-branch-automatically-by-webhook/"/>
    <id>https://finisky.github.io/en/git-sync-remote-branch-automatically-by-webhook/</id>
    <published>2023-01-08T15:01:23.000Z</published>
    <updated>2023-01-24T14:30:12.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;How to make your local repository always sync with GitHub repository?
The answer is webhook.&lt;/p&gt;
&lt;p&gt;When the repo received a push event, GitHub will send a
&lt;code&gt;POST&lt;/code&gt; request to the webhook URL with details of any
subscribed events. What we need to do is to implement a webhook (on
local side) which performs &lt;code&gt;git pull&lt;/code&gt; to keep sync with
remote.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="python" scheme="https://finisky.github.io/tags/python/"/>
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>2022 对话系统进展</title>
    <link href="https://finisky.github.io/dialog-system-progress-2022/"/>
    <id>https://finisky.github.io/dialog-system-progress-2022/</id>
    <published>2023-01-08T04:29:09.000Z</published>
    <updated>2023-02-08T06:43:06.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;2022年随着ChatGPT的大火而结束，最近一年的时间各巨头相继推出了许多表现出色的对话系统，有意思的是大家前进的方向不谋而合，不再专注模型结构和规模，而转向实用性：如何让一个对话系统更有用、更安全、更理解用户意图？&lt;/p&gt;
&lt;p&gt;对话系统在过去一年里的主要提升得益如下三点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;大模型&lt;/strong&gt;：对话系统的基础，规模大才有足够的通用表示能力&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;从人工反馈学习
(RLHF)&lt;/strong&gt;：通过人工标注不同模型输出，使模型更好地与用户意图align，甚至更小的模型可达到同样效果&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;搜索API&lt;/strong&gt;：使回复有所参考，内容更具体更有用，避免胡说八道
(hallucination)&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
    <category term="Reinforcement Learning" scheme="https://finisky.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>BlenderBot 3 对话系统简析</title>
    <link href="https://finisky.github.io/blenderbot3-summary/"/>
    <id>https://finisky.github.io/blenderbot3-summary/</id>
    <published>2023-01-06T12:12:01.000Z</published>
    <updated>2023-01-06T16:01:46.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Meta AI在2022年8月发布了新一代的对话系统 BlenderBot
3，希望通过这样一个公开的demo收集更多的真实数据来改进对话系统，使它变得更安全、更有用。&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://ai.facebook.com/blog/blenderbot-3-a-175b-parameter-publicly-available-chatbot-that-improves-its-skills-and-safety-over-time/&quot;&gt;BlenderBot
3: A 175B parameter, publicly available chatbot that improves its skills
and safety over time&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2208.03188&quot;&gt;BlenderBot 3: a deployed
conversational agent that continually learns to responsibly
engage&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;BlenderBot 3 (BB3) 只对在美国的成人开放，只用英文对话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We present BlenderBot 3 (BB3), an open-domain dialogue model that we
have deployed as an English speaking conversational agent on a public
website accessible by adults in the United States.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;此研究的主要目的与&lt;a
href=&quot;/sparrow-summary/&quot;&gt;Sparrow&lt;/a&gt;最接近，使对话更responsible &amp;amp;
useful:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of this research program is then to explore how to construct
models that continue to improve from such interactions both in terms of
becoming more responsible and more useful.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这个tech
report包括了BB3部署的细节，包括UI设计，本文主要关注模型部分。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>DeepMind Sparrow 对话系统简析</title>
    <link href="https://finisky.github.io/sparrow-summary/"/>
    <id>https://finisky.github.io/sparrow-summary/</id>
    <published>2022-12-27T12:06:39.000Z</published>
    <updated>2022-12-27T12:35:06.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Sparrow是DeepMind在今年9月底发布的对话系统，主打的点在&quot;helpful,
correct, and
harmless&quot;。总体来看，思路也是&quot;alignment&quot;，即让对话机器人的回复与用户的意图更贴合。在技术路线上，也是采用reinforcement
learning from human
feedback，通过定义一批规则，让模型更好地向期望的对话方向推进;
此外，对于事实型的问题，参考搜索出的内容给出回复。&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://www.deepmind.com/blog/building-safer-dialogue-agents&quot;&gt;Building
safer dialogue agents&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2209.14375&quot;&gt;Improving alignment of
dialogue agents via targeted human judgements&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
    <category term="Reinforcement Learning" scheme="https://finisky.github.io/tags/Reinforcement-Learning/"/>
    
  </entry>
  
  <entry>
    <title>为什么不接ChatGPT到微信公号？</title>
    <link href="https://finisky.github.io/chatgpt-for-official-account/"/>
    <id>https://finisky.github.io/chatgpt-for-official-account/</id>
    <published>2022-12-16T02:08:02.000Z</published>
    <updated>2022-12-16T02:42:55.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;ChatGPT火爆全网，要是能接到自己的微信公众号后台，岂不美哉？&lt;/p&gt;
&lt;p&gt;想必有此想法的同志不止我一人，上周末就研究了一下，有几个问题需要解决。&lt;/p&gt;
&lt;p&gt;首先就是ChatGPT
API，最关键的问题没有之一，OpenAI并没有官方API支持。不过github上早有人反向工程破解了此API，Python实现：&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
</feed>
