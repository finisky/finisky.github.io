<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Finisky Garden</title>
  <icon>https://finisky.github.io/icon.png</icon>
  <subtitle>NLP, Software Engineering and Product Design</subtitle>
  <link href="https://finisky.github.io/atom.xml" rel="self"/>
  
  <link href="https://finisky.github.io/"/>
  <updated>2022-10-20T03:36:36.000Z</updated>
  <id>https://finisky.github.io/</id>
  
  <author>
    <name>finisky</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>这么个玩意儿也能赚钱？</title>
    <link href="https://finisky.github.io/muyu-app/"/>
    <id>https://finisky.github.io/muyu-app/</id>
    <published>2022-10-20T01:52:58.000Z</published>
    <updated>2022-10-20T03:36:36.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;一个看着非常简单的App：手机敲木鱼，居然能在App
Store上评分4.8，十几万的评论，还有App内购买赚钱，刷新认知不？&lt;/p&gt;
&lt;p&gt;这年头多少人绞尽脑汁做App都无人理睬，反倒被这么个极简的玩意儿割了韭菜，原因还是它抓住了用户的痛点。&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>WeLM: A Well-Read Pre-trained Language Model for Chinese 简读</title>
    <link href="https://finisky.github.io/welm-paper-summary/"/>
    <id>https://finisky.github.io/welm-paper-summary/</id>
    <published>2022-10-17T11:57:10.000Z</published>
    <updated>2022-10-17T12:07:12.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;微信最近有篇新闻刷屏： &lt;a
href=&quot;https://new.qq.com/rain/a/20221013A02P8400&quot;&gt;#
微信推出自研NLP大规模语言模型WeLM：零/少样本即可完成多种NLP任务&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;来看看这背后的技术原理又是什么：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2209.10372&quot;&gt;WeLM: A Well-Read
Pre-trained Language Model for Chinese&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Prompt" scheme="https://finisky.github.io/tags/Prompt/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>LaMDA: Language Models for Dialog Applications 简读</title>
    <link href="https://finisky.github.io/lamda-paper-summary/"/>
    <id>https://finisky.github.io/lamda-paper-summary/</id>
    <published>2022-10-14T10:08:12.000Z</published>
    <updated>2022-10-14T10:10:09.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Google今年发布的聊天机器人LaMDA确实惊艳，之前一个Google员工与它对话后，声称它已经有了自我意识，还上了热搜。今天就来看看这机器人背后的原理是什么。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;关键词：&lt;/strong&gt; 大模型，高质量人工标注数据。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2201.08239&quot;&gt;LaMDA: Language Models for
Dialog Applications&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;论文的标题很大，有50多个作者，挺有意思。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Transformer" scheme="https://finisky.github.io/tags/Transformer/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Towards Boosting the Open-Domain Chatbot with Human Feedback 简读</title>
    <link href="https://finisky.github.io/diamonte-dataset-paper-summary/"/>
    <id>https://finisky.github.io/diamonte-dataset-paper-summary/</id>
    <published>2022-10-10T11:48:01.000Z</published>
    <updated>2022-10-10T11:59:09.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;百度最近放出来的一篇文章，发布了一个高质量中文多轮chitchat数据集Diamonte：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2208.14165&quot;&gt;Towards Boosting the
Open-Domain Chatbot with Human Feedback&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Diamonte数据集 &lt;a
href=&quot;https://www.luge.ai/#/luge/dataDetail?id=52&quot;&gt;下载地址&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Leveraging Similar Users for Personalized Language Modeling with Limited Data 简读</title>
    <link href="https://finisky.github.io/leveraging-similar-users-for-personalized-lm-paper-summary/"/>
    <id>https://finisky.github.io/leveraging-similar-users-for-personalized-lm-paper-summary/</id>
    <published>2022-10-08T11:28:27.000Z</published>
    <updated>2022-10-08T11:37:31.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;今天来看看这篇 ACL2022 的文章：&lt;/p&gt;
&lt;p&gt;[ACL2022] &lt;a
href=&quot;https://aclanthology.org/2022.acl-long.122/&quot;&gt;Leveraging Similar
Users for Personalized Language Modeling with Limited Data&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;解决的问题很容易理解，个性化语言模型在用户刚加入时缺少数据的冷启动问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Personalized language models are designed and trained to capture
language patterns specific to individual users.&lt;/p&gt;
&lt;p&gt;However, when a new user joins a platform and not enough text is
available, it is harder to build effective personalized language
models.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;思路也比较直接，使用新用户的少量数据在已有用户中找到相似的用户，然后用相似用户的数据进行语言模型的训练，从而解决数据稀疏的问题。&lt;/p&gt;
&lt;p&gt;实验论文，提出了三种不同的指标来进行用户相似度计算，实验证明 user
embedding + interpolate model效果最好。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>开卷有益？</title>
    <link href="https://finisky.github.io/kai-juan-you-yi/"/>
    <id>https://finisky.github.io/kai-juan-you-yi/</id>
    <published>2022-09-24T02:12:46.000Z</published>
    <updated>2022-10-08T05:28:01.000Z</updated>
    
    
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;开卷有益是一个成语，最早出自《与子俨等疏》。
意思是读书总有益处。常用以勉励人们勤奋好学，多读书就会受益。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;现在这年头，出书不要太容易，烂书也是出奇的多，开卷有益这词儿已经不适用了。就随口说说我最近翻过的几本烂书：《断舍离》，《组织的力量》，《底层逻辑》。&lt;/p&gt;</summary>
    
    
    
    <category term="Thoughts" scheme="https://finisky.github.io/categories/Thoughts/"/>
    
    
    <category term="Thoughts" scheme="https://finisky.github.io/tags/Thoughts/"/>
    
  </entry>
  
  <entry>
    <title>Long-Term Open-Domain Conversation 简读</title>
    <link href="https://finisky.github.io/long-term-open-domain-conversation-paper-summary/"/>
    <id>https://finisky.github.io/long-term-open-domain-conversation-paper-summary/</id>
    <published>2022-09-22T01:55:10.000Z</published>
    <updated>2022-09-22T07:29:50.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;今天来看看这篇 ACL2022 的文章：&lt;/p&gt;
&lt;p&gt;[ACL2022] &lt;a
href=&quot;https://aclanthology.org/2022.acl-long.356/&quot;&gt;Beyond Goldfish
Memory: Long-Term Open-Domain Conversation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;问题比较清楚，提升长期开放域对话的效果。题目用到一个梗：超越金鱼的7秒记忆，可以看出论文要解决的问题是跨越数小时甚至数天的会话。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注意：&lt;/strong&gt; 这里是“长期” (long-term) 对话，不是
“长程”对话，即对话时间跨度比较长的对话。&lt;/p&gt;
&lt;p&gt;本文同时发布了一个人与人进行长期对话的数据集
&lt;code&gt;Multi-Session Chat (MSC)&lt;/code&gt;，其中双方通过之前的会话互相了解对方的喜好，并在之后的对话中得以体现。&lt;/p&gt;
&lt;p&gt;在长期对话中，使用retrieval-augmented的方式，结合对上下文对话的摘要，可以达到超越传统encoder-decoder架构的模型效果。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
  </entry>
  
  <entry>
    <title>羊了个羊为什么这么火？</title>
    <link href="https://finisky.github.io/why-yang-le-ge-yang-so-hot/"/>
    <id>https://finisky.github.io/why-yang-le-ge-yang-so-hot/</id>
    <published>2022-09-18T11:02:56.000Z</published>
    <updated>2022-09-18T11:14:44.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;继跳一跳，2048，合成大西瓜等一众休闲小游戏爆火之后，羊了个羊最近频繁上热搜，甚至成了一个梗，它为什么爆红？有什么过人之处？今天就来扒一扒。&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering 简读</title>
    <link href="https://finisky.github.io/fusion-in-decoder-paper-summary/"/>
    <id>https://finisky.github.io/fusion-in-decoder-paper-summary/</id>
    <published>2022-09-13T11:36:46.000Z</published>
    <updated>2022-09-13T11:37:48.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;开放域问答常常需要借助外部知识生成更有信息量和准确的答复。当检索出相关知识后，如何将它们融入生成模型就是个问题。Fusion-in-Decoder
(FiD) 这篇文章提出了一个简单有效的方案。&lt;/p&gt;
&lt;p&gt;[EACL2021] [FiD] &lt;a
href=&quot;https://aclanthology.org/2021.eacl-main.74/&quot;&gt;Leveraging Passage
Retrieval with Generative Models for Open Domain Question
Answering&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
  </entry>
  
  <entry>
    <title>&#39;pandoc exited with code null&#39; 解决方案</title>
    <link href="https://finisky.github.io/pandoc-exited-with-code-null-solution/"/>
    <id>https://finisky.github.io/pandoc-exited-with-code-null-solution/</id>
    <published>2022-09-11T16:10:05.000Z</published>
    <updated>2022-09-11T15:58:07.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;随着博客文章的不断增加，Hexo生成这些文章需要的时间越来越长，最近居然能卡住几分钟，然后报错：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[ERROR][hexo-renderer-pandoc] pandoc exited with code null. at
Object._prettifyError
(/home/finisky/node_modules/nunjucks/src/lib.js:36:11)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;花了不少时间研究到底问题在哪，最终发现是VM的配置太低所致…… :-(&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
    <category term="Markdown" scheme="https://finisky.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>&#39;pandoc exited with code null&#39; Solution</title>
    <link href="https://finisky.github.io/en/pandoc-exited-with-code-null-solution/"/>
    <id>https://finisky.github.io/en/pandoc-exited-with-code-null-solution/</id>
    <published>2022-09-11T16:01:03.000Z</published>
    <updated>2022-09-11T15:58:07.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;As the post number increases, Hexo generate posts slower and slower.
Recently, it usually generates posts for several minutes and report the
following error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[ERROR][hexo-renderer-pandoc] pandoc exited with code null. at
Object._prettifyError
(/home/finisky/node_modules/nunjucks/src/lib.js:36:11)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I spent several hours to figure out the issue. Finally, I found the
root cause is ... VM memory is too small ... :-(&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
    <category term="Markdown" scheme="https://finisky.github.io/tags/Markdown/"/>
    
  </entry>
  
  <entry>
    <title>Long Time No See! Open-Domain Conversation with Long-Term Persona Memory 简读</title>
    <link href="https://finisky.github.io/long-time-no-see-paper-summary/"/>
    <id>https://finisky.github.io/long-time-no-see-paper-summary/</id>
    <published>2022-09-11T11:21:36.000Z</published>
    <updated>2022-09-11T13:42:31.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;对话系统中的个性化，或者说带有人设的AI对话机器人是个挺热的研究问题。随着虚拟人的爆火，如何能打造千人千面与用户沟通的AI，也就自然登上了舞台。今天就来看一篇ACL2022findings的文章：&lt;/p&gt;
&lt;p&gt;[ACL2022findings] &lt;a
href=&quot;https://aclanthology.org/2022.findings-acl.207.pdf&quot;&gt;Long Time No
See! Open-Domain Conversation with Long-Term Persona Memory&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;很多对话系统不能很好地利用用户对话的长程记忆，从而影响对话效果。百度的这篇文章提出了一个新任务
&lt;code&gt;Long-term Memory Conversation (LeMon)&lt;/code&gt; 并发布了对应的数据集
DuLeMon。该系统可以在用户和AI对话的过程中动态提取有用的Persona
Memory，并在之后的对话中同时考虑双方的Persona Memory进行更好的对话。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
  </entry>
  
  <entry>
    <title>AI虚拟主播带货是不是个好生意？</title>
    <link href="https://finisky.github.io/aianchor/"/>
    <id>https://finisky.github.io/aianchor/</id>
    <published>2022-08-22T01:42:06.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;随着元宇宙概念的兴起，AI虚拟主播也跟着又火起来了，但AI虚拟主播真是个好生意吗？&lt;/p&gt;
&lt;p&gt;AI虚拟主播大致可分为两类，一类是纯的AI虚拟主播，另一类是真人驱动的AI虚拟主播。后者要解决的是真人出镜的问题，本文主要讨论的是前者。&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>Hexo去LeanCloud依赖</title>
    <link href="https://finisky.github.io/hexormleancloud/"/>
    <id>https://finisky.github.io/hexormleancloud/</id>
    <published>2022-08-08T16:26:09.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;7.19日，收到了LeanCloud的邮件，大意如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;8 月 1 日起，LeanCloud 国际版共享域名不再向中国大陆提供服务&lt;/p&gt;
&lt;p&gt;为履行合规责任，降低平台风险，LeanCloud 国际版共享域名将于 2022 年 8
月 1
日起不再向中国大陆的最终用户提供服务，国际版共享域名仅服务于海外用户。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;静态网站的状态存取是个痛点。好消息是本站使用Hexo
NexT主题，天然集成了文章阅读量的功能，后端存储是LeanCloud，仅需配置&lt;code&gt;app_id&lt;/code&gt;与&lt;code&gt;app_key&lt;/code&gt;。而评论系统是另一个坑，一年前
&lt;a
href=&quot;/hexowaline&quot;&gt;切换到了Waline&lt;/a&gt;，一举攻克了这个难题，但当时Waline也依赖于LeanCloud。&lt;/p&gt;
&lt;p&gt;这次LeanCloud国际版共享域名不向中国大陆提供服务改动，对Waline无影响，因为Waline的前端部署在Vercel海外节点。&lt;strong&gt;但如果网站面向大陆用户，文章阅读量统计会受影响。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;因此，考虑将本站去LeanCloud依赖。方法很简单，将文章阅读量切换至Waline，同时Waline的后端存储改用MongoDB。去依赖需要你有一台服务器，自建MongoDB，或者直接使用
&lt;a href=&quot;https://www.mongodb.com/pricing&quot;&gt;MongoDB Atlas的免费版&lt;/a&gt;
。&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="MongoDB" scheme="https://finisky.github.io/tags/MongoDB/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
    <category term="Hexo Extension" scheme="https://finisky.github.io/tags/Hexo-Extension/"/>
    
    <category term="Serverless" scheme="https://finisky.github.io/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>FiniCounter: A Website Vistor Counter</title>
    <link href="https://finisky.github.io/finicounterimpl.en/"/>
    <id>https://finisky.github.io/finicounterimpl.en/</id>
    <published>2022-08-07T09:20:59.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Static website such as Hexo/Hugo/Jekyll is very popular recent years.
It is fast, easy to write, deploy and host. However, no free lunch: it
is non-trivial to store dynamic information such as pageview counts and
comments under the serverless architecture. This site uses Waline to
implement article view count and comment system.&lt;/p&gt;
&lt;p&gt;Accidently I found that we do not have a full site pageview counter.
Waline has post-level counter instead of site-level one.&lt;/p&gt;
&lt;p&gt;Just DIY: FiniCounter. Use Vercel serverless function as the web API
framework, MongoDB as the storage. When a user comes to any page of the
site, we invoke the count API through fetch API, increment the counter
in the MongoDB, return the updated value and display in the page.&lt;/p&gt;
&lt;p&gt;Initially I want to develop a tool for myself. After I finish it, I
decide to make it as a public &lt;strong&gt;free&lt;/strong&gt; service :-) . &lt;a
href=&quot;https://finicounter.vercel.app/en&quot;&gt;FiniCounter&lt;/a&gt; looks like
this:&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://cdn.jsdelivr.net/gh/finisky/finicounter/finicounterdemo.en.png&quot;
alt=&quot;FiniCounter Demo&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="MongoDB" scheme="https://finisky.github.io/tags/MongoDB/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
    <category term="Hexo Extension" scheme="https://finisky.github.io/tags/Hexo-Extension/"/>
    
    <category term="Hugo" scheme="https://finisky.github.io/tags/Hugo/"/>
    
    <category term="Serverless" scheme="https://finisky.github.io/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>FiniCounter: 静态网站访问量统计工具</title>
    <link href="https://finisky.github.io/finicounterimpl/"/>
    <id>https://finisky.github.io/finicounterimpl/</id>
    <published>2022-08-07T05:20:03.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;静态博客如Hexo/Hugo/Jekyll近些年很流行，markdown写作，一键生成部署，无需后端，可托管在各种网站平台，非常方便。但正因为无后端，动态信息的存取就成为了痛点：文章阅读数统计，评论系统等等。本站采用的是Hexo+Waline的方式实现文章阅读数统计与评论系统，最近也去掉了LeanCloud的依赖，所有数据使用MongoDB存储。&lt;/p&gt;
&lt;p&gt;突然发现缺少一个全站访问量统计的功能，Waline目前不支持。大多数静态网站使用不蒜子，但看到由于使用人数众多，常常出现502错误和服务不稳定的情况。遂考虑自行开发这样的一个服务：FiniCounter。使用Vercel
Serverless
Function作为Web框架，MongoDB为后端存储。用户访问任意页面时，通过Fetch
API调用Serverless
Function，在MongoDB中计数加1并返回最新计数，在前端展示。&lt;/p&gt;
&lt;p&gt;本想开发个小工具自己用，后来发现天然支持多用户，独乐乐不如众乐乐，大家一起用吧
:-)。效果展示：&lt;a
href=&quot;https://finicounter.vercel.app/&quot;&gt;FiniCounter&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://cdn.jsdelivr.net/gh/finisky/finicounter/finicounterdemo.png&quot;
alt=&quot;FiniCounter Demo&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Hexo" scheme="https://finisky.github.io/categories/Hexo/"/>
    
    
    <category term="Hexo" scheme="https://finisky.github.io/tags/Hexo/"/>
    
    <category term="MongoDB" scheme="https://finisky.github.io/tags/MongoDB/"/>
    
    <category term="NexT" scheme="https://finisky.github.io/tags/NexT/"/>
    
    <category term="Hexo Extension" scheme="https://finisky.github.io/tags/Hexo-Extension/"/>
    
    <category term="Hugo" scheme="https://finisky.github.io/tags/Hugo/"/>
    
    <category term="Serverless" scheme="https://finisky.github.io/tags/Serverless/"/>
    
  </entry>
  
  <entry>
    <title>抖音为什么如此成功？</title>
    <link href="https://finisky.github.io/douyinproduct/"/>
    <id>https://finisky.github.io/douyinproduct/</id>
    <published>2022-07-24T01:55:35.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;抖音自2016年9月于今日头条孵化上线，定位为适合中国大陆年轻人的音乐短视频社区，应用为垂直音乐的UGC短视频。从数据来看，抖音主站在2021年第一季度的平均日活已过6亿，非常惊人，可见用户对于抖音产品的认可和依赖。同时，笔者周围有不少人的抖音都是装了又卸，卸了又装，感叹：刷抖音太费时间了，一不小心几个小时就过去了。那么，抖音是如何在互联网行业中突出重围，脱颖而出的呢？&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/douyin.jpg&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>为什么微信能做支付，支付宝做不了社交</title>
    <link href="https://finisky.github.io/wechatvsalipay/"/>
    <id>https://finisky.github.io/wechatvsalipay/</id>
    <published>2022-07-15T01:50:21.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;关于&quot;为什么微信能做支付，支付宝做不了社交&quot;这个问题之前有过很多讨论，最近看到一个最直接直观的解释是，因为应用场景的包含关系不同。&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/wechatvsalipay.jpeg&quot; /&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Product" scheme="https://finisky.github.io/categories/Product/"/>
    
    
    <category term="Product" scheme="https://finisky.github.io/tags/Product/"/>
    
  </entry>
  
  <entry>
    <title>Rollback Stylish Chrome Extension</title>
    <link href="https://finisky.github.io/rollbackstylish.en/"/>
    <id>https://finisky.github.io/rollbackstylish.en/</id>
    <published>2022-07-13T01:50:43.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;&lt;a
href=&quot;https://chrome.google.com/webstore/detail/stylish-custom-themes-for/fjnbnpbmkenffdnngjfgmeleoegfcffe?hl=en&quot;&gt;Stylish&lt;/a&gt;
used to be an excellent Chrome extension. It is able to customize css
style for any website. I used this extension to change font to Monaco
for many years.&lt;/p&gt;
&lt;p&gt;Unfortunately, a recent auto update (July 6, 2022) makes it
completely unusable: seems that the custom css style is applied after
loading the page, so the page will keep the original font until finished
loading the whole page and suddenly change to the custom style. Besides,
the extension UI has a big change which cannot load properly.&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/stylishcsseffect.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Check the latest user review and found lots of 1 star bad review:&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/stylishcomments.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;So I investigate how to rollback to an old version Stylish and
disable update.&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
  <entry>
    <title>回滚老版本Stylish Chrome插件</title>
    <link href="https://finisky.github.io/rollbackstylish/"/>
    <id>https://finisky.github.io/rollbackstylish/</id>
    <published>2022-07-13T01:39:43.000Z</published>
    <updated>2022-08-29T03:55:42.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;(从前) &lt;a
href=&quot;https://chrome.google.com/webstore/detail/stylish-custom-themes-for/fjnbnpbmkenffdnngjfgmeleoegfcffe?hl=en&quot;&gt;Stylish&lt;/a&gt;
是个特别好的Chrome插件，可以自定义不同的css
style，覆盖网站原有的风格和字体。我使用Stylish主要是将网页本身的英文字体改为Monaco，中文字体是雅黑。&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/stylishcsseffect.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;不幸的是，最近一次的版本自动升级 (July 6, 2022)
让插件彻底不可用了：看起来css需要在整个网页加载完毕之后才进行覆盖，导致网页字体在原字体和Monaco之间跳转切换，闪瞎眼。此外，UI也进行了大改，设置style的入口变得很深且常常加载不出来，非常闹心。&lt;/p&gt;
&lt;p&gt;看下这插件最新的User review，一水的一星差评：&lt;/p&gt;
&lt;p&gt;&lt;img
src=&quot;https://raw.githubusercontent.com/finisky/finiskyimages/master/stylishcomments.png&quot; /&gt;&lt;/p&gt;
&lt;p&gt;那么如何使用老版本的Stylish并阻止它自动更新呢？&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
</feed>
