<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Finisky Garden</title>
  <icon>https://finisky.github.io/icon.png</icon>
  <subtitle>NLP, 软件工程, 产品设计</subtitle>
  <link href="https://finisky.github.io/atom.xml" rel="self"/>
  
  <link href="https://finisky.github.io/"/>
  <updated>2024-11-04T17:29:24.000Z</updated>
  <id>https://finisky.github.io/</id>
  
  <author>
    <name>finisky</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Building Large-Scale Social Network Graphs with MongoDB</title>
    <link href="https://finisky.github.io/en/building-large-scale-social-network-graphs-with-mongodb/"/>
    <id>https://finisky.github.io/en/building-large-scale-social-network-graphs-with-mongodb/</id>
    <published>2024-11-04T16:59:12.000Z</published>
    <updated>2024-11-04T17:29:24.000Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Nowadays, many popular apps incorporate social network features, such
as Twitter, WhatsApp, and Facebook. These platforms need to scale</summary>
        
      
    
    
    
    <category term="MongoDB" scheme="https://finisky.github.io/categories/MongoDB/"/>
    
    
    <category term="C#" scheme="https://finisky.github.io/tags/C/"/>
    
    <category term="MongoDB" scheme="https://finisky.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>用MongoDB构建大规模社交网络关系链</title>
    <link href="https://finisky.github.io/building-large-scale-social-network-graphs-with-mongodb/"/>
    <id>https://finisky.github.io/building-large-scale-social-network-graphs-with-mongodb/</id>
    <published>2024-11-04T13:59:48.000Z</published>
    <updated>2024-11-04T17:29:24.000Z</updated>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;如今许多App都涉及社交网络，如 Twitter、WhatsApp</summary>
        
      
    
    
    
    <category term="MongoDB" scheme="https://finisky.github.io/categories/MongoDB/"/>
    
    
    <category term="C#" scheme="https://finisky.github.io/tags/C/"/>
    
    <category term="MongoDB" scheme="https://finisky.github.io/tags/MongoDB/"/>
    
  </entry>
  
  <entry>
    <title>TypeError: Argument has incorrect type (expected numpy.ndarray, got DataFrame) 解决方案</title>
    <link href="https://finisky.github.io/argument-incorrect-type-expected-ndarray/"/>
    <id>https://finisky.github.io/argument-incorrect-type-expected-ndarray/</id>
    <published>2024-11-02T04:20:29.000Z</published>
    <updated>2024-11-02T04:27:22.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;在conda环境中升级软件包后，talib无法接受DataFrame作为输入，错误信息如下所示：&lt;code&gt;TypeError: Argument &#39;xxx&#39; has incorrect type (expected numpy.ndarray, got DataFrame)&lt;/code&gt;：&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Traceback (most recent call last):
  File &amp;quot;&amp;#x2F;data&amp;#x2F;1.py&amp;quot;, line 7, in &amp;lt;module&amp;gt;
    df[&amp;#39;SMA_5&amp;#39;] &amp;#x3D; ta.SMA(df[&amp;#39;Close&amp;#39;], timeperiod&amp;#x3D;5)
  File &amp;quot;&amp;#x2F;data&amp;#x2F;miniconda3&amp;#x2F;envs&amp;#x2F;a&amp;#x2F;lib&amp;#x2F;python3.10&amp;#x2F;site-packages&amp;#x2F;talib&amp;#x2F;__init__.py&amp;quot;, line 64, in wrapper
    result &amp;#x3D; func(*_args, **_kwds)
TypeError: Argument &amp;#39;real&amp;#39; has incorrect type (expected numpy.ndarray, got DataFrame)&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;大多数网络搜索结果都具有误导性，比如将df转换为np数组。由于在更新软件包之前代码能够正常运行，因此问题应为软件包不兼容的问题。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="python" scheme="https://finisky.github.io/tags/python/"/>
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>TypeError: Argument has incorrect type (expected numpy.ndarray, got DataFrame) Solution</title>
    <link href="https://finisky.github.io/en/argument-incorrect-type-expected-ndarray/"/>
    <id>https://finisky.github.io/en/argument-incorrect-type-expected-ndarray/</id>
    <published>2024-11-02T04:06:56.000Z</published>
    <updated>2024-11-02T04:27:22.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;After upgrading packages in a conda env, talib cannot accept
dataframe as input, the error message looks like
&lt;code&gt;TypeError: Argument &#39;xxx&#39; has incorrect type (expected numpy.ndarray, got DataFrame)&lt;/code&gt;:&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Traceback (most recent call last):
  File &amp;quot;&amp;#x2F;data&amp;#x2F;1.py&amp;quot;, line 7, in &amp;lt;module&amp;gt;
    df[&amp;#39;SMA_5&amp;#39;] &amp;#x3D; ta.SMA(df[&amp;#39;Close&amp;#39;], timeperiod&amp;#x3D;5)
  File &amp;quot;&amp;#x2F;data&amp;#x2F;miniconda3&amp;#x2F;envs&amp;#x2F;a&amp;#x2F;lib&amp;#x2F;python3.10&amp;#x2F;site-packages&amp;#x2F;talib&amp;#x2F;__init__.py&amp;quot;, line 64, in wrapper
    result &amp;#x3D; func(*_args, **_kwds)
TypeError: Argument &amp;#39;real&amp;#39; has incorrect type (expected numpy.ndarray, got DataFrame)&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Most of the web search results are misleading, like changing the df
into np array. Since the code works before updating packages, the
problem should be package incompatibility issue.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="python" scheme="https://finisky.github.io/tags/python/"/>
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Windows 11 drive D usable but not visible in File Explorer</title>
    <link href="https://finisky.github.io/en/drive-d-usable-but-not-visible-in-file-explorer/"/>
    <id>https://finisky.github.io/en/drive-d-usable-but-not-visible-in-file-explorer/</id>
    <published>2024-10-12T16:40:35.000Z</published>
    <updated>2024-10-12T16:42:39.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Today, I encountered a strange issue in Windows 11 where the D drive
was visible in the Disk Management tool but not in File Explorer. I
searched online for many solutions, such as updating drivers in Device
Manager, disabling and re-enabling the device, using
&lt;code&gt;diskpart&lt;/code&gt; to delete and recreate the partition, changing the
volume label, changing the drive letter, etc., but none worked.&lt;/p&gt;
&lt;h2 id=&quot;problem-description&quot;&gt;Problem Description&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;A new D drive, visible in &lt;code&gt;diskmgmt.msc&lt;/code&gt; Disk Management,
everything seemed normal. It could even be accessed in File Explorer
(though the drive wasn’t displayed in the left sidebar).&lt;/li&gt;
&lt;li&gt;The D drive could be used normally, such as via the command
line.&lt;/li&gt;
&lt;li&gt;Changing the drive letter to “E” or another letter made it visible
in File Explorer, but switching it back to “D” caused it to disappear
again.&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
  <entry>
    <title>Win11 D盘可用但在文件浏览器中不可见</title>
    <link href="https://finisky.github.io/drive-d-usable-but-not-visible-in-file-explorer/"/>
    <id>https://finisky.github.io/drive-d-usable-but-not-visible-in-file-explorer/</id>
    <published>2024-10-12T16:13:33.000Z</published>
    <updated>2024-10-12T16:42:39.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;今天遇到Win11中 D
盘在磁盘管理工具中显示可用，但在文件管理器中却不可见的诡异情况。网上搜了许多方案，如在设备管理器中更新驱动，禁用再启用设备，用&lt;code&gt;diskpart&lt;/code&gt;重新删除新建分区，改卷标改盘符等等都不好使。&lt;/p&gt;
&lt;h2 id=&quot;问题描述&quot;&gt;问题描述&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;新建D盘，在&lt;code&gt;diskmgmt.msc&lt;/code&gt;磁盘管理器中可见，一切正常。甚至能打开文件浏览器（只是左栏不显示磁盘）&lt;/li&gt;
&lt;li&gt;D盘可正常使用，如在命令行中使用&lt;/li&gt;
&lt;li&gt;修改盘符为“E”或其他盘符，文件浏览器中就可见了，但改回“D”又会消失&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
  <entry>
    <title>Use az cli to Query Multiple Fields of Resource Information</title>
    <link href="https://finisky.github.io/en/use-az-cli-to-query-multiple-fields/"/>
    <id>https://finisky.github.io/en/use-az-cli-to-query-multiple-fields/</id>
    <published>2024-09-11T13:53:33.000Z</published>
    <updated>2024-09-11T13:53:53.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Use &lt;code&gt;az cli&lt;/code&gt; to query multiple fields of VM information.
Here we need to use JMESPath language to implement it.&lt;/p&gt;
&lt;p&gt;Typically, we will use &lt;code&gt;az vm show&lt;/code&gt; to get the detailed VM
information:&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-bash&quot; data-language=&quot;bash&quot;&gt;&lt;code class=&quot;language-bash&quot;&gt;$ az vm show &lt;span class=&quot;token parameter variable&quot;&gt;-g&lt;/span&gt; Linux &lt;span class=&quot;token parameter variable&quot;&gt;-n&lt;/span&gt; alpha &lt;span class=&quot;token parameter variable&quot;&gt;-d&lt;/span&gt; &lt;span class=&quot;token parameter variable&quot;&gt;-o&lt;/span&gt; table
Name    ResourceGroup    PowerState    PublicIps     Fqdns    Location    Zones
------  ---------------  ------------  ------------  -------  ----------  -------
alpha   Linux            VM running    &lt;span class=&quot;token number&quot;&gt;11.1&lt;/span&gt;.111.111           eastasia    &lt;span class=&quot;token number&quot;&gt;1&lt;/span&gt;&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>基于LLM评估搜索系统</title>
    <link href="https://finisky.github.io/llm-can-accurately-predict-searcher-preferences/"/>
    <id>https://finisky.github.io/llm-can-accurately-predict-searcher-preferences/</id>
    <published>2024-08-29T00:30:26.000Z</published>
    <updated>2024-08-29T08:39:21.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;搜索系统的评估和调优很大程度上依赖于相关性标签——这些标签标注了某个文档对特定搜索和搜索者是否有用。理想情况下，这些标签来自真实的搜索用户，但要大规模收集这些数据非常困难，所以典型的实验依赖于第三方标注人员，但他们也可能产生不准确的标注。标注质量一般通过持续的审核、培训和监控来管理。&lt;/p&gt;
&lt;p&gt;微软（Bing搜索组）在SIGIR&#39;24提出了一种“反其道而行之”的方法：从真实的用户获取反馈，并利用这些反馈来选择一个与之相符的LLM及其提示词，然后令该LLM大规模地产生标签。实验表明，LLM的准确性与人工标注者相当，并且在找到最佳系统和最难的查询方面同样有用。&lt;/p&gt;
&lt;p&gt;[SIGIR2024] &lt;a
href=&quot;https://www.microsoft.com/en-us/research/publication/large-language-models-can-accurately-predict-searcher-preferences/&quot;&gt;#
Large Language Models can Accurately Predict Searcher
Preferences&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
    <category term="Search" scheme="https://finisky.github.io/tags/Search/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT擅长搜索排序吗？</title>
    <link href="https://finisky.github.io/is-chatgpt-good-at-search-ranking/"/>
    <id>https://finisky.github.io/is-chatgpt-good-at-search-ranking/</id>
    <published>2024-07-21T14:15:25.000Z</published>
    <updated>2024-07-21T16:11:06.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;大语言模型在各种与语言相关的任务中表现出了显著的零样本泛化能力，包括搜索引擎。然而，现有的工作主要利用LLM的生成能力进行信息检索，而不是直接进行段落排序。这篇EMNLP2023的论文(Outstanding
Paper)研究了LLM是否擅长搜索排序的问题。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://aclanthology.org/2023.emnlp-main.923/&quot;&gt;# Is ChatGPT
Good at Search? Investigating Large Language Models as Re-Ranking
Agents&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Search" scheme="https://finisky.github.io/tags/Search/"/>
    
  </entry>
  
  <entry>
    <title>Rethinking the Role of Token Retrieval in Multi-Vector Retrieval简读</title>
    <link href="https://finisky.github.io/xtr-summary/"/>
    <id>https://finisky.github.io/xtr-summary/</id>
    <published>2024-06-30T10:58:25.000Z</published>
    <updated>2024-07-23T01:57:31.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;之前写过深度检索模型的介绍：&lt;a href=&quot;/retrievermodels/&quot;&gt;#
深度文本检索模型：DPR, PolyEncoders, DCBERT,
ColBERT&lt;/a&gt;，今天来看看DeepMind在NeurIPS
2024上的文章，对多向量检索模型（Multi-Vector
Retrieval）ColBERT进行了改进：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/2304.01982&quot;&gt;Rethinking the Role of
Token Retrieval in Multi-Vector Retrieval&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;多向量检索模型由于使Query与Doc进行词元级别的交互，因此在许多信息检索基准测试中达到了SOTA。然而，其非线性评分函数无法扩展到数百万个文档，这就需要一个三阶段的推理过程：通过词元检索检索初始候选，访问所有词元向量，并对初始候选文档进行评分。非线性评分函数应用于每个候选文档的所有词元向量，使得推理过程复杂且缓慢。XTR
引入了新的目标函数，鼓励模型首先检索最重要的文档词元，对词元检索的改进使得
XTR
可以仅使用检索到的词元来对候选文档排序，而不是文档中的所有词元，因此其成本比
ColBERT 低两到三个数量级。在流行的 BEIR 基准测试中，XTR
在没有任何蒸馏的情况下，将 NDCG@10 提升了 2.8。&lt;/p&gt;
&lt;p&gt;主要改进点：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;仅使用检索到的doc token而非全部doc token进行相似度计算&lt;/li&gt;
&lt;li&gt;解决了检索训练和推理之间的gap&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="Search" scheme="https://finisky.github.io/tags/Search/"/>
    
  </entry>
  
  <entry>
    <title>AI搜索与大模型应用的一些思考</title>
    <link href="https://finisky.github.io/thoughts-on-ai-search-and-llm-applications/"/>
    <id>https://finisky.github.io/thoughts-on-ai-search-and-llm-applications/</id>
    <published>2024-05-10T01:28:36.000Z</published>
    <updated>2024-07-23T01:57:31.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;最近读到一篇有趣的文章，讨论了当前许多新的AI搜索产品是否会取代Google：&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://www.theverge.com/24111326/ai-search-perplexity-copilot-you-google-review&quot;&gt;Here’s
why AI search engines really can’t kill Google&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;先简要地看下这篇文章在说什么：&lt;/p&gt;
&lt;p&gt;如果要取代Google，那么这些新的产品必须可以完成Google能做的所有事情。于是，作者先收集了Top100的Google搜索查询，然后将它们输入到当前最好的一些AI搜索产品中。作者认为，虽然在某些情况下，基于LLM的搜索比一页Google搜索结果有用，但在大多数情况下，AI搜索取代Google还是相当困难的。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
    <category term="Search" scheme="https://finisky.github.io/tags/Search/"/>
    
  </entry>
  
  <entry>
    <title>WinSCP Transfer to Temporary Filename Not Working</title>
    <link href="https://finisky.github.io/en/winscp-transfer-to-temp-filename-not-working/"/>
    <id>https://finisky.github.io/en/winscp-transfer-to-temp-filename-not-working/</id>
    <published>2024-05-08T01:10:23.000Z</published>
    <updated>2024-05-08T06:17:00.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;In WinSCP, I found that when uploading file to the server, the file
doesn&#39;t have a temporary filename extension &quot;.filepart&quot;.&lt;/p&gt;
&lt;p&gt;Enable temporary filename for all files in &quot;Preferences -&amp;gt;
Transfer -&amp;gt; Endurance&quot; still does not work.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
    <category term="Ubuntu" scheme="https://finisky.github.io/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu Server Freezes After Several Minutes</title>
    <link href="https://finisky.github.io/en/ubuntu-freezes-after-several-minutes/"/>
    <id>https://finisky.github.io/en/ubuntu-freezes-after-several-minutes/</id>
    <published>2024-04-18T04:36:16.000Z</published>
    <updated>2024-04-18T04:54:38.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;After upgrading Ubuntu 20.04 LTS to Ubuntu 22.04LTS, the server
always freezes after ~10 minutes. All services are down, cannot ssh,
connect to serial console but cannot input. However, this issue never
happen before release upgrade.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://finisky.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://finisky.github.io/tags/Linux/"/>
    
    <category term="Ubuntu" scheme="https://finisky.github.io/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Word Wildcard Replace Bug When Track Changes</title>
    <link href="https://finisky.github.io/en/word-wildcard-replace-bug-when-track-changes/"/>
    <id>https://finisky.github.io/en/word-wildcard-replace-bug-when-track-changes/</id>
    <published>2024-04-03T01:18:43.000Z</published>
    <updated>2024-04-05T08:33:22.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;Cannot believe that Word has such a bug: when tracking changes,
wildcard replacement cannot correctly work.&lt;/p&gt;
&lt;p&gt;I want to batch replace English parentheses with Chinese parentheses,
so I use wildcard replacement:&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Find What: \((*)\)
Options: Use Wildcards
Replace With: （\1）&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For example, for &quot;(abc)&quot;, the expected result is &quot;（abc）&quot;, however,
the result is &quot;abc（）&quot;.&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
  <entry>
    <title>Word追踪修订时通配符替换Bug</title>
    <link href="https://finisky.github.io/word-wildcard-replace-bug-when-track-changes/"/>
    <id>https://finisky.github.io/word-wildcard-replace-bug-when-track-changes/</id>
    <published>2024-04-03T01:16:33.000Z</published>
    <updated>2024-04-05T08:33:22.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;没想到浓眉大眼的Office
Word居然还有这种Bug：在追踪修订时，通配符不能正确替换。&lt;/p&gt;
&lt;p&gt;在处理一个大型文档时，需要批量将英文括号替换成中文括号，因此需要使用到通配符替换：&lt;/p&gt;
&lt;pre class=&quot;line-numbers language-none&quot;&gt;&lt;code class=&quot;language-none&quot;&gt;Find What: \((*)\)
Options: Use Wildcards
Replace With: （\1）&lt;span aria-hidden=&quot;true&quot; class=&quot;line-numbers-rows&quot;&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;预期行为是：将“(abc)”替换为“（abc）”，却没料到被替换成了“abc（）”。&lt;/p&gt;</summary>
    
    
    
    <category term="Misc" scheme="https://finisky.github.io/categories/Misc/"/>
    
    
  </entry>
  
  <entry>
    <title>为什么语言模型的本质是压缩器？</title>
    <link href="https://finisky.github.io/language-modeling-is-compression-summary/"/>
    <id>https://finisky.github.io/language-modeling-is-compression-summary/</id>
    <published>2024-03-26T11:05:56.000Z</published>
    <updated>2024-03-26T11:03:53.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;最早听说语言模型的本质是压缩器的想法是在&lt;a
href=&quot;/fireside-talk-openai-ceo-summary/&quot;&gt;黄仁勋和Ilya的围炉对谈&lt;/a&gt;，当时只是直觉上觉得这个说法很有意思，但却没想明白原理是什么。2023年9月，DeepMind写论文进一步论证了语言建模与压缩的等价性：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2309.10668&quot;&gt;# Language Modeling Is
Compression&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;长期以来，人们已经确认预测模型可以转化为无损压缩器，反之亦然。值得注意的是，近年来，机器学习领域一直专注于训练规模越来越大且功能强大的自监督语言模型。由于这些大语言模型展示了很强的预测能力，它们自然而然地也被认为是强大的压缩器。文中研究者主张通过压缩的视角来审视预测问题，并依此评估大型基座模型的压缩能力。实验证明大语言模型也是强大的通用预测器，语言模型即压缩的视角为扩展定律和上下文学习提供了新的见解。例如，Chinchilla
70B虽然主要用文本训练，但却能将ImageNet
patches和LibriSpeech样本压缩到其原始大小的43.4%和16.4%，分别超过了领域特定的压缩器，如PNG（58.5%）和FLAC（30.3%）。最后，研究者证实基于预测与压缩的等价性可以使用任何压缩器来构建条件生成模型。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;本文试图用简洁的语言（无公式）来说明“语言建模即压缩”的思想。原论文的思路是借助算术编码的原理和过程，然后将语言模型建模的过程与算术编码过程进行映射并证明它们等价。这个思路有些类似于NP难问题的证明：将一个问题在多项式时间归约成已知的某个NP难问题。&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>大模型的涌现能力是幻象？</title>
    <link href="https://finisky.github.io/llm-emergent-ability-is-mirage-summary/"/>
    <id>https://finisky.github.io/llm-emergent-ability-is-mirage-summary/</id>
    <published>2024-01-05T17:15:46.000Z</published>
    <updated>2024-01-05T17:20:38.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;“涌现能力”可谓是大模型的神来之笔：这些能力在小规模模型中不存在，而仅在大规模模型中存在。涌现能力的神奇之处就在于两点：第一，锐利性，似乎它们瞬间从不存在变为存在；第二，不可预测性，不知道在什么规模的模型上就突现了。&lt;/p&gt;
&lt;p&gt;涌现能力相关的讨论在大模型出圈之后一直被津津乐道，尤其是在训练出的模型能力不达预期时，时常背锅：可能是模型不够大，所以不具备这样的能力。问题来了，涌现能力是否真的是大规模模型才拥有的魔法？&lt;/p&gt;
&lt;p&gt;NeurIPS 2023的Main Track Outstanding
Paper的二者之一，提出了对涌现能力的一种解释：对于特定任务和模型，在分析模型输出时，涌现能力的出现是由于研究人员选择的衡量指标所致，而非模型行为随着规模扩大而发生了根本性变化。具体而言，非线性或不连续的衡量标准会产生明显的涌现能力，而线性或连续的度量标准会导致模型性能的平滑、连续、可预测的变化。&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://blog.neurips.cc/2023/12/11/announcing-the-neurips-2023-paper-awards/&quot;&gt;#
Announcing the NeurIPS 2023 Paper Awards&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2304.15004&quot;&gt;# Are Emergent Abilities
of Large Language Models a Mirage?&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>ChatGPT一周年：开源大模型迎头赶上？</title>
    <link href="https://finisky.github.io/open-source-llm-vs-chatgpt/"/>
    <id>https://finisky.github.io/open-source-llm-vs-chatgpt/</id>
    <published>2023-12-26T01:59:45.000Z</published>
    <updated>2023-12-26T02:08:38.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;一篇有趣的综述文章，写于ChatGPT问世一周年之时，总结了开源大型语言模型（LLM）在过去一年中的发展情况。首先介绍了开源LLM的兴起，以及它们如何在各种自然语言处理任务中取得了显著的进展。然后讨论了开源LLM与闭源LLM之间的竞争，以及它们在性能和应用方面的差异。文中提到了一些具体的研究成果和进展，包括知识获取、情感分析、代码生成等。最后，论文探讨了开源LLM的未来发展方向，以及在伦理和安全方面的挑战和应对措施。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2311.16989&quot;&gt;# ChatGPT&#39;s One-year
Anniversary: Are Open-Source Large Language Models Catching up?&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>小模型的惊人能力: Phi-2</title>
    <link href="https://finisky.github.io/phi2-the-surprising-power-summary/"/>
    <id>https://finisky.github.io/phi2-the-surprising-power-summary/</id>
    <published>2023-12-13T10:18:16.000Z</published>
    <updated>2023-12-14T04:55:11.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;过去半年，MSR发布了一套名为&lt;code&gt;Phi&lt;/code&gt;的小模型（SLMs），取得了卓越的性能表现。其中第一个模型，1.3B
的&lt;code&gt;Phi-1&lt;/code&gt;，实现了在现有SLMs中对Python编码的最佳性能（在HumanEval和MBPP数据集上）。随后，他们将注意力扩展到常识推理和语言理解，并创建了一个新的
1.3B
模型，命名为&lt;code&gt;Phi-1.5&lt;/code&gt;，其性能相当于规模更大5倍的模型。&lt;/p&gt;
&lt;p&gt;最近MSR发布了&lt;code&gt;Phi-2&lt;/code&gt;，一个 2.7B
的语言模型，展示了卓越的推理和语言理解能力，表现出小于 13B
语言模型的最好效果。在各种测试中，&lt;code&gt;Phi-2&lt;/code&gt;与规模大达25倍的模型差不多或获胜，主要归功于模型规模和训练数据方面的创新。MSR已经在Azure
AI Studio模型目录中提供了Phi-2，以促进语言模型的研究和开发。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Phi-2&lt;/code&gt; 未放出细节的技术报告，具体可参考原博客：&lt;/p&gt;
&lt;p&gt;&lt;a
href=&quot;https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/&quot;&gt;#
Phi-2: The surprising power of small language models&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;第一代&lt;code&gt;Phi-1&lt;/code&gt;解读：&lt;a
href=&quot;/textbooks-are-all-you-need-summary/&quot;&gt;数据为王: Textbooks Are All
You Need&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
  <entry>
    <title>Skywork: A More Open Bilingual Foundation Model 简读</title>
    <link href="https://finisky.github.io/skywork-summary/"/>
    <id>https://finisky.github.io/skywork-summary/</id>
    <published>2023-11-10T11:18:16.000Z</published>
    <updated>2023-11-11T02:29:44.000Z</updated>
    
    
    <summary type="html">&lt;p&gt;昆仑的天工模型一直走开源路线，最近放出了技术报告，其中关于预训练模型刷榜作弊的部分引发了广泛的讨论，把大家心照不宣的事情首次放到了台面上
:-)。本文来看下这篇技术报告的亮点(非全文精读，仅摘要有趣的点，细节可阅读原论文)。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2310.19341&quot;&gt;# Skywork: A More Open
Bilingual Foundation Model&lt;/a&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/categories/Machine-Learning/"/>
    
    
    <category term="Machine Learning" scheme="https://finisky.github.io/tags/Machine-Learning/"/>
    
    <category term="NLP" scheme="https://finisky.github.io/tags/NLP/"/>
    
    <category term="NLG" scheme="https://finisky.github.io/tags/NLG/"/>
    
    <category term="Language Model" scheme="https://finisky.github.io/tags/Language-Model/"/>
    
  </entry>
  
</feed>
